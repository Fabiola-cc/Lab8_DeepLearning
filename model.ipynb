{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "573c2e25",
   "metadata": {},
   "source": [
    "# Laboratorio 8\n",
    "Datos de [\"Store Item Demand Forecasting Challenge\"](https://www.kaggle.com/competitions/demand-forecasting-kernels-only/data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1d55446f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11b1f42",
   "metadata": {},
   "source": [
    "### Carga y preparación de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0c3d6bb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos cargados: (913000, 4)\n",
      "\n",
      "Primeras filas:\n",
      "        date  store  item  sales\n",
      "0 2013-01-01      1     1     13\n",
      "1 2013-01-02      1     1     11\n",
      "2 2013-01-03      1     1     14\n",
      "3 2013-01-04      1     1     13\n",
      "4 2013-01-05      1     1     10\n",
      "\n",
      "Información del dataset:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 913000 entries, 0 to 912999\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Non-Null Count   Dtype         \n",
      "---  ------  --------------   -----         \n",
      " 0   date    913000 non-null  datetime64[ns]\n",
      " 1   store   913000 non-null  int64         \n",
      " 2   item    913000 non-null  int64         \n",
      " 3   sales   913000 non-null  int64         \n",
      "dtypes: datetime64[ns](1), int64(3)\n",
      "memory usage: 27.9 MB\n",
      "None\n",
      "\n",
      "Valores faltantes\n",
      "date     0\n",
      "store    0\n",
      "item     0\n",
      "sales    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# usamos solo los datos en train para validar las respuestas luego\n",
    "df = pd.read_csv(\"data/train.csv\", parse_dates=[\"date\"])\n",
    "\n",
    "# Revisión de estructura\n",
    "print(f\"Datos cargados: {df.shape}\")\n",
    "print(\"\\nPrimeras filas:\")\n",
    "print(df.head())\n",
    "\n",
    "# Convertir fecha a datetime\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "print(\"\\nInformación del dataset:\")\n",
    "print(df.info())\n",
    "\n",
    "# Revisar valores faltantes\n",
    "print(\"\\nValores faltantes\")\n",
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0086e264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filas duplicadas: 0\n",
      "\n",
      "Estadísticas de ventas:\n",
      "count    913000.000000\n",
      "mean         52.250287\n",
      "std          28.801144\n",
      "min           0.000000\n",
      "25%          30.000000\n",
      "50%          47.000000\n",
      "75%          70.000000\n",
      "max         231.000000\n",
      "Name: sales, dtype: float64\n",
      "\n",
      "Outliers detectados: 357 (0.04%)\n"
     ]
    }
   ],
   "source": [
    "# ya que no hay datos faltantes en el dataset no es necesario trabajarlo\n",
    "\n",
    "# Verificar duplicados\n",
    "duplicados = df.duplicated().sum()\n",
    "print(f\"Filas duplicadas: {duplicados}\")\n",
    "if duplicados > 0:\n",
    "    df = df.drop_duplicates()\n",
    "    \n",
    "# Estadísticas básicas\n",
    "print(f\"\\nEstadísticas de ventas:\")\n",
    "print(df['sales'].describe())\n",
    "    \n",
    "# Detectar outliers usando IQR\n",
    "Q1 = df['sales'].quantile(0.15)\n",
    "Q3 = df['sales'].quantile(0.85)\n",
    "IQR = Q3 - Q1\n",
    "outliers = df[(df['sales'] < Q1 - 1.5 * IQR) | (df['sales'] > Q3 + 1.5 * IQR)]\n",
    "print(f\"\\nOutliers detectados: {len(outliers)} ({len(outliers)/len(df)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "50363279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.describe of              date  store  item  sales  store_id  item_id  sales_scaled\n",
      "92     2013-04-03      1     1     24         0        0      0.037037\n",
      "95     2013-04-06      1     1     23         0        0      0.000000\n",
      "103    2013-04-14      1     1     26         0        0      0.111111\n",
      "121    2013-05-02      1     1     23         0        0      0.000000\n",
      "140    2013-05-21      1     1     24         0        0      0.037037\n",
      "...           ...    ...   ...    ...       ...      ...           ...\n",
      "912995 2017-12-27     10    50     63         9       49      0.661017\n",
      "912996 2017-12-28     10    50     59         9       49      0.593220\n",
      "912997 2017-12-29     10    50     74         9       49      0.847458\n",
      "912998 2017-12-30     10    50     62         9       49      0.644068\n",
      "912999 2017-12-31     10    50     82         9       49      0.983051\n",
      "\n",
      "[650577 rows x 7 columns]>\n"
     ]
    }
   ],
   "source": [
    "# Eliminar outliers extremos \n",
    "df = df[(df[\"sales\"] >= Q1) & (df[\"sales\"] <= Q3)]\n",
    "print(df.describe)\n",
    "\n",
    "# Ordenar por fecha\n",
    "df = df.sort_values('date').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "01e34753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformación de datos\n",
    "# Codificar store e item\n",
    "store_enc = LabelEncoder()\n",
    "item_enc = LabelEncoder()\n",
    "df[\"store_id\"] = store_enc.fit_transform(df[\"store\"])\n",
    "df[\"item_id\"] = item_enc.fit_transform(df[\"item\"])\n",
    "\n",
    "n_stores = df[\"store_id\"].nunique()\n",
    "n_items = df[\"item_id\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5ce4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizamos ventas por serie\n",
    "scalers = {}  # un scaler por serie\n",
    "for s in range(n_stores):\n",
    "    for i in range(n_items):\n",
    "        mask = (df[\"store_id\"]==s) & (df[\"item_id\"]==i)\n",
    "        scaler = MinMaxScaler()\n",
    "        df.loc[mask, \"sales_scaled\"] = scaler.fit_transform(df.loc[mask, [\"sales\"]])\n",
    "        scalers[(s,i)] = scaler"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
